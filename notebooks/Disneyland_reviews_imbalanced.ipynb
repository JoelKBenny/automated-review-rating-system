{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aecdea92-f87e-49bb-98a8-1ee930ab94bb",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e73cdd8c-9ad1-452a-b152-1d83a1a2782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7463f9-ab00-46b6-bc0d-778bba71e4ee",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb484d2-1e40-4d1c-8179-b044ed58e9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/joelk/automated-review-rating-system/data/Kaggle Datasets/Disneyland_Reviews.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4818b64-eef6-46ba-8c7b-8a98a41000d9",
   "metadata": {},
   "source": [
    "### Data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90b22e5c-67a5-4cc0-9449-064260ea3494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_ID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year_Month</th>\n",
       "      <th>Reviewer_Location</th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Branch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>670772142</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>Australia</td>\n",
       "      <td>If you've ever been to Disneyland anywhere you...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>670682799</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-5</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Its been a while since d last time we visit HK...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>670623270</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Thanks God it wasn   t too hot or too humid wh...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>670607911</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>Australia</td>\n",
       "      <td>HK Disneyland is a great compact park. Unfortu...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>670607296</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>the location is not in the city, took around 1...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Review_ID  Rating Year_Month     Reviewer_Location  \\\n",
       "0  670772142       4     2019-4             Australia   \n",
       "1  670682799       4     2019-5           Philippines   \n",
       "2  670623270       4     2019-4  United Arab Emirates   \n",
       "3  670607911       4     2019-4             Australia   \n",
       "4  670607296       4     2019-4        United Kingdom   \n",
       "\n",
       "                                         Review_Text               Branch  \n",
       "0  If you've ever been to Disneyland anywhere you...  Disneyland_HongKong  \n",
       "1  Its been a while since d last time we visit HK...  Disneyland_HongKong  \n",
       "2  Thanks God it wasn   t too hot or too humid wh...  Disneyland_HongKong  \n",
       "3  HK Disneyland is a great compact park. Unfortu...  Disneyland_HongKong  \n",
       "4  the location is not in the city, took around 1...  Disneyland_HongKong  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f57e8e0-ce2b-4faf-8440-63a38598bf76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_ID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year_Month</th>\n",
       "      <th>Reviewer_Location</th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Branch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42651</th>\n",
       "      <td>1765031</td>\n",
       "      <td>5</td>\n",
       "      <td>missing</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>i went to disneyland paris in july 03 and thou...</td>\n",
       "      <td>Disneyland_Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42652</th>\n",
       "      <td>1659553</td>\n",
       "      <td>5</td>\n",
       "      <td>missing</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2 adults and 1 child of 11 visited Disneyland ...</td>\n",
       "      <td>Disneyland_Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42653</th>\n",
       "      <td>1645894</td>\n",
       "      <td>5</td>\n",
       "      <td>missing</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>My eleven year old daughter and myself went to...</td>\n",
       "      <td>Disneyland_Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42654</th>\n",
       "      <td>1618637</td>\n",
       "      <td>4</td>\n",
       "      <td>missing</td>\n",
       "      <td>United States</td>\n",
       "      <td>This hotel, part of the Disneyland Paris compl...</td>\n",
       "      <td>Disneyland_Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42655</th>\n",
       "      <td>1536786</td>\n",
       "      <td>4</td>\n",
       "      <td>missing</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>I went to the Disneyparis resort, in 1996, wit...</td>\n",
       "      <td>Disneyland_Paris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Review_ID  Rating Year_Month Reviewer_Location  \\\n",
       "42651    1765031       5    missing    United Kingdom   \n",
       "42652    1659553       5    missing            Canada   \n",
       "42653    1645894       5    missing      South Africa   \n",
       "42654    1618637       4    missing     United States   \n",
       "42655    1536786       4    missing    United Kingdom   \n",
       "\n",
       "                                             Review_Text            Branch  \n",
       "42651  i went to disneyland paris in july 03 and thou...  Disneyland_Paris  \n",
       "42652  2 adults and 1 child of 11 visited Disneyland ...  Disneyland_Paris  \n",
       "42653  My eleven year old daughter and myself went to...  Disneyland_Paris  \n",
       "42654  This hotel, part of the Disneyland Paris compl...  Disneyland_Paris  \n",
       "42655  I went to the Disneyparis resort, in 1996, wit...  Disneyland_Paris  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e9e7fb2-283b-4cba-a8e6-103cf5e42248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42656 entries, 0 to 42655\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Review_ID          42656 non-null  int64 \n",
      " 1   Rating             42656 non-null  int64 \n",
      " 2   Year_Month         42656 non-null  object\n",
      " 3   Reviewer_Location  42656 non-null  object\n",
      " 4   Review_Text        42656 non-null  object\n",
      " 5   Branch             42656 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cf674cf-710e-4f66-abe4-cf63edd984f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review_ID            0\n",
       "Rating               0\n",
       "Year_Month           0\n",
       "Reviewer_Location    0\n",
       "Review_Text          0\n",
       "Branch               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9a736e-598a-49ac-9650-e27e2f81729c",
   "metadata": {},
   "source": [
    "### Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0380a1ac-de64-4565-8b15-fb6e2416475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['Review_Text', 'Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55b30b1f-cd1e-4bf9-bb95-b3bd23418380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42633, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b03abd0e-416d-4105-b389-7fe481bdaebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews with conflicting ratings: 1\n"
     ]
    }
   ],
   "source": [
    "conflicts = df.groupby('Review_Text')['Rating'].nunique()\n",
    "conflicting_reviews = conflicts[conflicts > 1].index\n",
    "print(\"Number of reviews with conflicting ratings:\", len(conflicting_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a38d1c2-3a5e-4e6b-ae6e-3cce78b7a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['Review_Text'].isin(conflicting_reviews)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0703c4c-af03-4c51-b70f-18ca4d8b9cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42631, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8804b95f-3486-4344-be86-73dcbe49f90e",
   "metadata": {},
   "source": [
    "### Removing Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e47beda0-6f96-4144-812a-9480ede9aab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Review_ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8c3dcf0-6f97-4a7c-8bc0-4753f3e669f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Reviewer_Location', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c762a72-3e36-4749-9758-3aff8160fdbf",
   "metadata": {},
   "source": [
    "### Normalizing \"review_text\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7183909-b1e1-4f17-aee2-0d9d04e6638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_review(text):\n",
    "   \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "\n",
    "    # Converting all reviews into Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Removing HTML tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "    # Removing URls\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "\n",
    "    # Removing punctuation and special characters\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "    # Removing Emojis\n",
    "    text = text.encode(\"ascii\",\"ignore\").decode(\"ascii\")\n",
    "\n",
    "    # Tokenizing the reveiews\n",
    "    tokens = text.split()\n",
    "\n",
    "    # Removing stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    # Filtering Too short and long reviews\n",
    "    if len(tokens) < 3 or len(tokens) > 100: # the longest review has a word count of 970. but the average, median, Q3 of wordcount was 66,52,77 respectievlely. \n",
    "        return None\n",
    "\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db70e0d6-624f-49ee-a512-214d23dcb2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_review'] = df['Review_Text'].apply(normalize_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da538d72-6941-47ba-84b7-5b0e57bf4b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['cleaned_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4f6fe8-b52f-4714-a46e-0082c6b0ff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad317d2-ad15-4789-bdd3-185081623eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c909905d-f38d-44d0-b34a-eb2f72cd31d0",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e13080a-1ba7-477b-9f33-4821dca41539",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "sns.countplot(x='Rating', data=df, palette='viridis', order=sorted(df['Rating'].unique()))\n",
    "plt.title(\"Rating Distribution\", fontsize=16, pad=20)\n",
    "plt.xlabel(\"Rating\", fontsize=12)\n",
    "plt.ylabel(\"Number of Reviews\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4a6ddf-9e30-4b24-b26b-8175d522eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df['cleaned_review'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bd25dd-3e25-42e5-93c8-53947c79087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee33ae3-983a-4fbb-8b1d-40dab524e96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4845254e-e8dc-4d57-97d2-bbf575e33f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "sns.histplot(data=df, x=\"word_count\", hue=\"Rating\", bins=30, multiple=\"stack\", palette=\"viridis\")\n",
    "plt.title(\"Histogram of Word Counts by Rating\", fontsize=16, pad=20)\n",
    "plt.xlabel(\"Number of Words\")\n",
    "plt.ylabel(\"Count of Reviews\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a34f45-f141-4905-bd4b-70938f9decda",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rating in sorted(df[\"Rating\"].unique()):\n",
    "    print(f\"\\n======================= Rating: {rating} =======================\\n\")\n",
    "    sample_reviews = df[df[\"Rating\"] == rating][\"Review_Text\"].sample(n=5, random_state=42)  \n",
    "    for i, review in enumerate(sample_reviews, 1):\n",
    "        print(f\"{i}. {review}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd783926-9798-4f70-9a2f-05e9aef8ea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rating'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aaf6ca-8165-4e3d-a3ec-e28f3d4dca91",
   "metadata": {},
   "source": [
    "### Resampling Ratings with samples lesser than 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76ebba2-a452-4baa-b097-2148b8664c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# target min samples per class\n",
    "min_samples = 2000  \n",
    "\n",
    "df_imbalanced_sampled = df.copy()\n",
    "new_dfs = []\n",
    "\n",
    "for rating, group in df_imbalanced_sampled.groupby(\"Rating\"):\n",
    "    if len(group) < min_samples:\n",
    "        # Upsample minority class\n",
    "        group = resample(group, \n",
    "                         replace=True, \n",
    "                         n_samples=min_samples, \n",
    "                         random_state=42)\n",
    "    new_dfs.append(group)\n",
    "\n",
    "df_imbalanced_sampled = pd.concat(new_dfs)\n",
    "print(df_imbalanced_sampled['Rating'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e0a8e2-af19-406b-8ec8-8ecf245ed53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "sns.countplot(x='Rating', data=df_imbalanced_sampled, palette='viridis', order=sorted(df_imbalanced_sampled['Rating'].unique()))\n",
    "plt.title(\"Rating Distribution after Resampling\", fontsize=16, pad=20)\n",
    "plt.xlabel(\"Rating\", fontsize=12)\n",
    "plt.ylabel(\"Number of Reviews\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361e522f-ff31-4e22-84ae-0821855472e4",
   "metadata": {},
   "source": [
    "### Train Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae1cd2c-bea1-425f-8f44-5ca8988818f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23fc57c-05d2-4368-8bc5-dbec8ae42c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_imbalanced_sampled['cleaned_review']\n",
    "y = df_imbalanced_sampled['Rating']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0d09f5-493a-41d0-8eb7-2ab81e3eb2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set class distribution:\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2752018a-f3bd-4fda-81e8-86ccca987759",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTest set class distribution:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8073c699-4659-4f9a-b142-3d3ca0172876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appying preprocessing to train test sets\n",
    "\n",
    "x_train_clean = x_train.apply(normalize_review)\n",
    "x_test_clean  = x_test.apply(normalize_review)\n",
    "\n",
    "#Removing rows that didn't pass the preprocessing\n",
    "train_mask = x_train_clean.notna()\n",
    "test_mask  = x_test_clean.notna()\n",
    "\n",
    "x_train_clean, y_train = x_train_clean[train_mask], y_train[train_mask]\n",
    "x_test_clean, y_test   = x_test_clean[test_mask], y_test[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3473d7e-5f47-4dbe-9b12-dbe096601e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df_new = pd.DataFrame({\n",
    "    'cleaned_review': x_test_clean,\n",
    "    'rating': y_test\n",
    "})\n",
    "\n",
    "# Export to CSV\n",
    "output_filename = 'imbalanced_test_set.csv'\n",
    "df_new.to_csv(output_filename, index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934f91e5-4a6f-48c2-820a-71cf9e601055",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c57f93-ffa5-4e09-bb97-d799b7c2d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer_B = TfidfVectorizer(max_features=15000,\n",
    "                             ngram_range=(1,2))\n",
    "                            \n",
    "\n",
    "# fitting on training data\n",
    "x_train_vec = vectorizer_B.fit_transform(x_train_clean)\n",
    "\n",
    "# Transforming the test data\n",
    "x_test_vec = vectorizer_B.transform(x_test_clean)\n",
    "\n",
    "print(x_train_vec.shape, x_test_vec.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6003ec-8944-4564-9805-72ca0738313f",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630f875c-2ebf-4196-97ac-15e4a379c410",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d3504b-ddfe-4564-b46f-d3a2d813399c",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73715f0-cf02-4368-88c0-c282245a8d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce0426c-b6ec-4ad8-9675-c3e3eba2162e",
   "metadata": {},
   "source": [
    "#### Initiating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7309f52-faaf-4ea7-8085-e962d8f82b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr_model = LogisticRegression(C=1.0,\n",
    "#                             solver='lbfgs',\n",
    "#                             multi_class='multinomial',\n",
    "#                             max_iter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c63e216-7fcc-45fd-947e-f8882f2fd0e7",
   "metadata": {},
   "source": [
    "#### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9717992-e824-40e9-b990-faeadf2edee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr_model.fit(x_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03f3b22-e69e-4dee-9f60-2f35099fde2a",
   "metadata": {},
   "source": [
    "#### Making predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a62c32-1323-4854-9257-44f6bce16f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_lr = lr_model.predict(x_test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7e8e8a-15a3-4b9a-930a-f61acaef1cd9",
   "metadata": {},
   "source": [
    "#### Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8463f631-7e9d-4b01-9af4-5cabda167fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Accuracy \n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "#Precision\n",
    "precision_lr = precision_score(y_test, y_pred_lr, average='weighted')\n",
    "\n",
    "#Recall\n",
    "recall_lr = recall_score(y_test, y_pred_lr, average='weighted')\n",
    "\n",
    "#f1\n",
    "f1_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "\n",
    "#confusion matrix\n",
    "\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "print(\"\\nAccuracy       : \",accuracy_lr)\n",
    "print(\"Precision      : \",precision_lr)\n",
    "print(\"Recall         : \",recall_lr)\n",
    "print(\"F1 Score       : \",f1_lr)\n",
    "print(\"\\nConfusion Matrix : \\n\",cm_lr)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5183ab7-fe28-4afa-8b04-2977eac6f2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "labels = [1,2,3,4,5]\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted Rating\", fontsize=12)\n",
    "plt.ylabel(\"Actual Rating\", fontsize=12)\n",
    "plt.title(\"Heatmap of Confusion Matrix of Logistic Regression Model\", fontsize=16, pad=25)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c90e9a-876f-409c-8e46-a76ed4c07d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train_accuracy = lr_model.score(x_train_vec, y_train)\n",
    "test_accuracy = lr_model.score(x_test_vec, y_test)\n",
    "print(\"training data accuracy : \",train_accuracy)\n",
    "print(\"testing data accuracy : \",test_accuracy)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b103b4c6-d574-4b53-9694-300e746da0b2",
   "metadata": {},
   "source": [
    "### Inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be162ac-90e8-428a-b41e-b2991b16dc85",
   "metadata": {},
   "source": [
    "* The model performs well on Rating 1 & 5.\n",
    "* Middle ratings are more confused.\n",
    "* Bias towards rating 5 :\n",
    "  You can see many reviews for middle ratings (3,4) are predicted as rating 5.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a3c65b-8e79-4702-80f8-c886af045975",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9507fbed-f1e7-4c88-8074-4ba0681495e5",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010c4838-db2d-4d0d-8f64-dff69765f851",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50f252f-e7eb-4858-acfe-dbf02eb2c703",
   "metadata": {},
   "source": [
    "#### Initiating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463a3892-3b4e-4260-b5cc-91e456ab8740",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "rf_model = RandomForestClassifier(n_estimators=50,\n",
    "                                  random_state=42)\n",
    "                                  #max_depth=30,\n",
    "                                  #min_samples_split=5,\n",
    "                                  #min_samples_leaf=2)\n",
    "  \"\"\"                                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a05f57a-ffe0-4f65-a5df-8c0db3952268",
   "metadata": {},
   "source": [
    "#### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6000ab36-39d8-45c7-a430-5c7254dac914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf_model.fit(x_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc46c47-72ad-48dc-81b4-7eaf76717e42",
   "metadata": {},
   "source": [
    "#### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aae7e4-59ab-45f4-9b65-6871772df3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_rf = rf_model.predict(x_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9dab94-f8c5-413c-bb04-21298e421c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Accuracy \n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "#Precision\n",
    "precision_rf = precision_score(y_test, y_pred_rf, average='weighted')\n",
    "\n",
    "#Recall\n",
    "recall_rf = recall_score(y_test, y_pred_rf, average='weighted')\n",
    "\n",
    "#f1\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "\n",
    "#confusion matrix\n",
    "\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "print(\"\\nAccuracy       : \",accuracy_rf)\n",
    "print(\"Precision      : \",precision_rf)\n",
    "print(\"Recall         : \",recall_rf)\n",
    "print(\"F1 Score       : \",f1_rf)\n",
    "print(\"\\nConfusion Matrix : \\n\",cm_rf)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb1c762-969f-4b0d-b41e-ed0ae6534ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "labels = [1,2,3,4,5]\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted Rating\", fontsize=12)\n",
    "plt.ylabel(\"Actual Rating\", fontsize=12)\n",
    "plt.title(\"Heatmap of Confusion Matrix of Random Forest Model\", fontsize=16, pad=25)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdd6a38-fe02-4a1c-bb88-1901f3f2cbd7",
   "metadata": {},
   "source": [
    "### Inferences "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860fcec6-c0a0-441d-b09e-aaa0fb2c4388",
   "metadata": {},
   "source": [
    "* The Model is highly biased towards higher ratings:\n",
    "  The model heavily leans toward predicting higher ratings, confusing many 4-star Rating as 5-star.\n",
    "* Rating 1 & 2 are classified fairly well, showing that the model can capture clear negative sentiment patterns.\n",
    "* Rating 3 is more difficult for the model to distinguish (Overlapping with both positive & negative reiews.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7db148-a5a6-4af0-b365-513fc3e8fa0e",
   "metadata": {},
   "source": [
    "## SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6804f178-f494-495d-921e-bad9673133ef",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2552cc1f-e31c-493a-ad93-80bf793f6323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180e769c-76ea-40ac-a146-594b9ff0a896",
   "metadata": {},
   "source": [
    "#### Initiating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44bc330-7346-4cc5-8ff3-08f063078a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model_B = svm_model\n",
    "model_B = LinearSVC(random_state=42,\n",
    "                     C=0.5,\n",
    "                     max_iter=2000)\n",
    "                     #class_weight='balanced')\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17032426-2007-4547-b4ec-ffd39df999d2",
   "metadata": {},
   "source": [
    "#### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13179a1c-0d6d-4178-884f-07e14745b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.fit(x_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170eef86-7eca-46c1-8132-5d645215b223",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hasattr(vectorizer_B, \"idf_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc977db1-81ce-4bfd-8fc8-09f0b4dede14",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = model_B.predict(x_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7716ff0d-e47d-46eb-8ec6-ec20dbb3e6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model_B, \"C:/Users/joelk/automated-review-rating-system/models/Model_B.pkl\")\n",
    "joblib.dump(vectorizer_B, \"C:/Users/joelk/automated-review-rating-system/models/Vec_B.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d8638c-da17-4097-80fe-a8d54b3c9b7a",
   "metadata": {},
   "source": [
    "#### Evaluation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f18355-af3c-4cb8-8ed3-60a08006c54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy \n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "#Precision\n",
    "precision_svm = precision_score(y_test, y_pred_svm, average='weighted')\n",
    "\n",
    "#Recall\n",
    "recall_svm = recall_score(y_test, y_pred_svm, average='weighted')\n",
    "\n",
    "#f1\n",
    "f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "\n",
    "#confusion matrix\n",
    "\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "print(\"\\nAccuracy       : \",accuracy_svm)\n",
    "print(\"Precision      : \",precision_svm)\n",
    "print(\"Recall         : \",recall_svm)\n",
    "print(\"F1 Score       : \",f1_svm)\n",
    "print(\"\\nConfusion Matrix : \\n\",cm_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd11e9a-3224-4df3-a65c-ef63006bde48",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1,2,3,4,5]\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted Rating\", fontsize=12)\n",
    "plt.ylabel(\"Actual Rating\", fontsize=12)\n",
    "plt.title(\"Heatmap of Confusion Matrix of SVM Model\", fontsize=16, pad=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a69b841-44fe-44e2-9836-66ac35a096b4",
   "metadata": {},
   "source": [
    "### Inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a879d791-df5d-4d40-aadc-98372ec147ee",
   "metadata": {},
   "source": [
    "* The model performs very well for Rating 1 & 5, correctly identifying most of them.\n",
    "* Middle Ratings 2, 3 and 4 show lower accuracy.\n",
    "* Misclassification between adjacent ratings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b7b38d-fb90-4b5e-b870-6780a09ccfa9",
   "metadata": {},
   "source": [
    "### Conslusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dbd3be-28e0-4389-a4d6-1ca567b7ac8a",
   "metadata": {},
   "source": [
    "After evaluating Logistic Regression, Random Forest, and SVM on the imbalanced review dataset, SVM emerges as the optimal model with the highest accuracy (67.7%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b1aaab-8007-4743-9649-710c605b626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Review\": x_test_clean,\n",
    "    \"Actual Rating\": y_test,\n",
    "    \"Predicted Rating\": y_pred_svm\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "sampled_reviews = (\n",
    "    results_df.groupby(\"Actual Rating\", group_keys=False)\n",
    "    .apply(lambda x: x.sample(n=5, random_state=42) if len(x) >= 5 else x)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "sampled_reviews.index = np.arange(1, len(sampled_reviews) + 1)\n",
    "sampled_reviews.index.name = \"S.No\"\n",
    "\n",
    "sampled_reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d92149-f91a-4214-bd6e-726b1d754045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
